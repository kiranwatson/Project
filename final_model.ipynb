{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WW1o-tqxI9wB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSkVPBkGJAqe",
        "outputId": "8b05b762-c6b0-4e2b-ccd4-d2d1a8975150"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the Data Paths\n",
        "TRAIN_PATH = '/content/drive/MyDrive/images1/train'\n",
        "VAL_PATH = '/content/drive/MyDrive/images1/val'\n",
        "TEST_PATH=\"/content/drive/MyDrive/images1/test\"\n"
      ],
      "metadata": {
        "id": "j3RFXfopJJf0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameters\n",
        "img_size = (299, 299, 3)\n",
        "num_classes = 2  # Binary classification: Glaucoma Negative and Glaucoma Positive\n",
        "epochs = 60\n",
        "batch_size = 32\n",
        "\n",
        "# Custom Data Generator\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "\n",
        "class CustomImageDataGenerator(ImageDataGenerator):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "    def flow_from_directory(self, directory, *args, **kwargs):\n",
        "        try:\n",
        "            return super().flow_from_directory(directory, *args, **kwargs)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing images in directory: {directory}. Skipping...\")\n",
        "            print(e)\n",
        "            return None  # Return None if there's an error\n"
      ],
      "metadata": {
        "id": "AD7VjgBrJTTQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def validate_images(directory):\n",
        "    invalid_images = []\n",
        "\n",
        "    # Iterate through all files in the directory\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            try:\n",
        "                # Open the image file\n",
        "                img_path = os.path.join(root, file)\n",
        "                img = Image.open(img_path)\n",
        "                img.close()  # Close the image file\n",
        "\n",
        "            except Exception as e:\n",
        "                # Add the path of the invalid image to the list\n",
        "                invalid_images.append(img_path)\n",
        "                print(f\"Error processing image: {img_path}. Skipping...\")\n",
        "                print(e)\n",
        "\n",
        "    return invalid_images\n",
        "\n",
        "# Directory containing the images\n",
        "directory = '/content/drive/MyDrive/images1/train'\n",
        "\n",
        "# Validate images\n",
        "invalid_images = validate_images(directory)\n",
        "\n",
        "# Print list of invalid images\n",
        "print(\"Invalid images:\")\n",
        "for img_path in invalid_images:\n",
        "    print(img_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPjMWfZYJWe0",
        "outputId": "1acaed84-fa14-44e5-e351-f56c77d41e2f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid images:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data generators\n",
        "train_datagen = CustomImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=60,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_datagen = CustomImageDataGenerator(rescale=1./255)\n",
        "test_datagen = CustomImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "nQHZKFj8J-xT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flow from directory\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    TRAIN_PATH,\n",
        "    target_size=img_size[:2],\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'  # Binary classification\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    VAL_PATH,\n",
        "    target_size=img_size[:2],\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary', # Binary classification\n",
        "    color_mode='rgb',\n",
        "    seed=2019\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    TEST_PATH,\n",
        "    target_size=img_size[:2],\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',  # Binary classification\n",
        "    color_mode='rgb',\n",
        "    shuffle=False,  # Set to False for test set\n",
        "    seed=2019\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pxwTw9pKMty",
        "outputId": "cc865928-f12c-4da8-c98f-4ece523822f6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 920 images belonging to 2 classes.\n",
            "Found 114 images belonging to 2 classes.\n",
            "Found 117 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "base_model = InceptionV3(include_top=False, weights='imagenet', input_shape=img_size)\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)  # Sigmoid for binary classification\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=RMSprop(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, min_lr=0.000001)\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIqXmy6sKSH0",
        "outputId": "71625812-c256-481b-8dc6-b2f05e55500d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 1s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure train_generator is defined and initialized\n",
        "if train_generator is None or not train_generator:\n",
        "    raise ValueError(\"`train_generator` is not properly initialized. Ensure it is defined and contains data.\")\n",
        "\n",
        "# Model training\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    validation_steps=len(val_generator),\n",
        "    callbacks=[reduce_lr, early_stop]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5VUGyi7KauW",
        "outputId": "d9744eae-1af6-468c-99bc-71bd2132aa2c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "29/29 [==============================] - 136s 3s/step - loss: 0.9821 - accuracy: 0.5163 - val_loss: 940.8917 - val_accuracy: 0.4912 - lr: 0.0010\n",
            "Epoch 2/60\n",
            "29/29 [==============================] - 47s 2s/step - loss: 0.7280 - accuracy: 0.5326 - val_loss: 0.7456 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 3/60\n",
            "29/29 [==============================] - 48s 2s/step - loss: 0.7091 - accuracy: 0.5326 - val_loss: 44.3975 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 4/60\n",
            "29/29 [==============================] - 46s 2s/step - loss: 0.7080 - accuracy: 0.5120 - val_loss: 14.1125 - val_accuracy: 0.4912 - lr: 0.0010\n",
            "Epoch 5/60\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.6714 - accuracy: 0.6000\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "29/29 [==============================] - 48s 2s/step - loss: 0.6714 - accuracy: 0.6000 - val_loss: 1.0224 - val_accuracy: 0.6579 - lr: 0.0010\n",
            "Epoch 6/60\n",
            "29/29 [==============================] - 50s 2s/step - loss: 0.6112 - accuracy: 0.6739 - val_loss: 0.6344 - val_accuracy: 0.6930 - lr: 1.0000e-04\n",
            "Epoch 7/60\n",
            "29/29 [==============================] - 48s 2s/step - loss: 0.5444 - accuracy: 0.7424 - val_loss: 0.6446 - val_accuracy: 0.7193 - lr: 1.0000e-04\n",
            "Epoch 8/60\n",
            "29/29 [==============================] - 48s 2s/step - loss: 0.4911 - accuracy: 0.7826 - val_loss: 0.6152 - val_accuracy: 0.7719 - lr: 1.0000e-04\n",
            "Epoch 9/60\n",
            "29/29 [==============================] - 47s 2s/step - loss: 0.4283 - accuracy: 0.7913 - val_loss: 0.5961 - val_accuracy: 0.6930 - lr: 1.0000e-04\n",
            "Epoch 10/60\n",
            "29/29 [==============================] - 48s 2s/step - loss: 0.3844 - accuracy: 0.8261 - val_loss: 0.5546 - val_accuracy: 0.7368 - lr: 1.0000e-04\n",
            "Epoch 11/60\n",
            "29/29 [==============================] - 48s 2s/step - loss: 0.3771 - accuracy: 0.8380 - val_loss: 0.5483 - val_accuracy: 0.6930 - lr: 1.0000e-04\n",
            "Epoch 12/60\n",
            "29/29 [==============================] - 48s 2s/step - loss: 0.3588 - accuracy: 0.8467 - val_loss: 0.5073 - val_accuracy: 0.7368 - lr: 1.0000e-04\n",
            "Epoch 13/60\n",
            "29/29 [==============================] - 48s 2s/step - loss: 0.3650 - accuracy: 0.8239 - val_loss: 0.4728 - val_accuracy: 0.7632 - lr: 1.0000e-04\n",
            "Epoch 14/60\n",
            "29/29 [==============================] - 47s 2s/step - loss: 0.3444 - accuracy: 0.8511 - val_loss: 0.3848 - val_accuracy: 0.8246 - lr: 1.0000e-04\n",
            "Epoch 15/60\n",
            "29/29 [==============================] - 48s 2s/step - loss: 0.3269 - accuracy: 0.8457 - val_loss: 0.3881 - val_accuracy: 0.8246 - lr: 1.0000e-04\n",
            "Epoch 16/60\n",
            "29/29 [==============================] - 47s 2s/step - loss: 0.3220 - accuracy: 0.8554 - val_loss: 0.3656 - val_accuracy: 0.8246 - lr: 1.0000e-04\n",
            "Epoch 17/60\n",
            "29/29 [==============================] - 48s 2s/step - loss: 0.3159 - accuracy: 0.8565 - val_loss: 0.4746 - val_accuracy: 0.7982 - lr: 1.0000e-04\n",
            "Epoch 18/60\n",
            "29/29 [==============================] - 47s 2s/step - loss: 0.2964 - accuracy: 0.8641 - val_loss: 0.3381 - val_accuracy: 0.8246 - lr: 1.0000e-04\n",
            "Epoch 19/60\n",
            "29/29 [==============================] - 48s 2s/step - loss: 0.2989 - accuracy: 0.8630 - val_loss: 0.3865 - val_accuracy: 0.8158 - lr: 1.0000e-04\n",
            "Epoch 20/60\n",
            "29/29 [==============================] - 48s 2s/step - loss: 0.2829 - accuracy: 0.8707 - val_loss: 0.2971 - val_accuracy: 0.8596 - lr: 1.0000e-04\n",
            "Epoch 21/60\n",
            "29/29 [==============================] - 47s 2s/step - loss: 0.2630 - accuracy: 0.8978 - val_loss: 0.3731 - val_accuracy: 0.8070 - lr: 1.0000e-04\n",
            "Epoch 22/60\n",
            "29/29 [==============================] - 48s 2s/step - loss: 0.2745 - accuracy: 0.8815 - val_loss: 0.3424 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 23/60\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.2655 - accuracy: 0.8859\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "29/29 [==============================] - 51s 2s/step - loss: 0.2655 - accuracy: 0.8859 - val_loss: 0.3893 - val_accuracy: 0.8158 - lr: 1.0000e-04\n",
            "Epoch 24/60\n",
            "29/29 [==============================] - 47s 2s/step - loss: 0.2542 - accuracy: 0.8826 - val_loss: 0.3823 - val_accuracy: 0.8070 - lr: 1.0000e-05\n",
            "Epoch 25/60\n",
            "29/29 [==============================] - 48s 2s/step - loss: 0.2353 - accuracy: 0.9120 - val_loss: 0.3694 - val_accuracy: 0.8158 - lr: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Evaluate the model on the validation set\n",
        "val_loss, val_accuracy = model.evaluate(val_generator, verbose=1)\n",
        "\n",
        "# Print the validation accuracy\n",
        "print(\"Validation Accuracy: {:.2f}%\".format(val_accuracy * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtOG0jg2Ke0N",
        "outputId": "5ec7b168-513a-439d-9693-f71d063b948a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 2s 528ms/step - loss: 0.2971 - accuracy: 0.8596\n",
            "Validation Accuracy: 85.96%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Load the image you want to predict\n",
        "image_path = '/content/drive/MyDrive/images1/test/glaucoma/Im332_g_ACRIMA.jpg'  \n",
        "img = image.load_img(image_path, target_size=(299, 299))  \n",
        "\n",
        "# Preprocess the image\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array /= 255.  # Rescale to [0, 1] as done in training\n",
        "\n",
        "# Perform prediction\n",
        "prediction = model.predict(img_array)\n",
        "\n",
        "# Map prediction to classes\n",
        "if prediction < 0.5:\n",
        "    print(\"Prediction: Glaucoma Positive\")\n",
        "else:\n",
        "    print(\"Prediction: Glaucoma Negative\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMWtZDxiQXQ1",
        "outputId": "b5296f5b-da38-4deb-8f17-e8613c6086f3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n",
            "Prediction: Glaucoma Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z_Q3j0AJQpSG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
